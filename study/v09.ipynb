{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from datetime import datetime as dt\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n",
      "torch.Size([1, 28, 28]) 9\n",
      "0:00:02.957989\n",
      "0:00:01.253965\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "trans = transforms.ToTensor()\n",
    "data_train = torchvision.datasets.FashionMNIST(root='../data', train=True, transform=trans)\n",
    "data_test = torchvision.datasets.FashionMNIST(root='../data', train=False, transform=trans)\n",
    "\n",
    "print(len(data_train), len(data_test))\n",
    "print(data_train[0][0].shape, data_train[0][1])\n",
    "\n",
    "size_batch = 256\n",
    "iter_train = data.DataLoader(data_train, size_batch, shuffle=True, num_workers=2)\n",
    "iter_test = data.DataLoader(data_test, size_batch, shuffle=False, num_workers=2)\n",
    "\n",
    "t0 = dt.now()\n",
    "for X_batch, y_batch in iter_train:\n",
    "    continue\n",
    "\n",
    "print(dt.now() - t0)\n",
    "t0 = dt.now()\n",
    "for X_batch, y_batch in iter_test:\n",
    "    continue\n",
    "\n",
    "print(dt.now() - t0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1212\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "num_in = 784\n",
    "num_out = 10\n",
    "W_model = torch.normal(0, 0.01, size=(num_in, num_out), requires_grad=True)\n",
    "b_model = torch.zeros(num_out, requires_grad=True)\n",
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    denom = X_exp.sum(1, keepdim=True)\n",
    "    return X_exp / denom\n",
    "\n",
    "def model(X):\n",
    "    return softmax(torch.matmul(X.reshape([-1, num_in]), W_model) + b_model)\n",
    "\n",
    "def cross_entropy(y_hat, y):\n",
    "    return -torch.log(y_hat[range(len(y_hat)), y])\n",
    "\n",
    "# evaluate\n",
    "def accuracy(y_hat, y):\n",
    "    y_hat = y_hat.argmax(axis=1)\n",
    "    return float((y_hat.type(y.dtype) == y).sum())\n",
    "\n",
    "def evaluate_accuracy(md, iter_data):\n",
    "    if isinstance(md, torch.nn.Module):\n",
    "        md.eval()\n",
    "\n",
    "    metric = [0.0, 0.0]\n",
    "    for X, y in iter_data:\n",
    "        metric[0] += accuracy(md(X), y)\n",
    "        metric[1] += y.numel()\n",
    "\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "print(evaluate_accuracy(model, iter_test))\n",
    "\n",
    "# abandon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, p-acc 0.7754\n",
      "epoch 2, p-acc 0.7987\n",
      "epoch 3, p-acc 0.8168\n",
      "epoch 4, p-acc 0.8183\n",
      "epoch 5, p-acc 0.8266\n",
      "epoch 6, p-acc 0.8267\n",
      "epoch 7, p-acc 0.8262\n",
      "epoch 8, p-acc 0.8296\n",
      "epoch 9, p-acc 0.8313\n",
      "epoch 10, p-acc 0.8206\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "lr_learn = 0.1\n",
    "epoch_learn = 10\n",
    "\n",
    "# model\n",
    "num_in = 784\n",
    "num_out = 10\n",
    "model = nn.Sequential(nn.Flatten(), nn.Linear(num_in, num_out))\n",
    "# def init_weights(md):\n",
    "#     if type(md) == nn.Linear:\n",
    "#         nn.init.normal_(md.weight, std=0.01)\n",
    "#\n",
    "# model.apply(init_weights)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.SGD(model.parameters(), lr=lr_learn)\n",
    "\n",
    "# training\n",
    "for epoch in range(epoch_learn):\n",
    "    for X_batch, y_batch in iter_train:\n",
    "        loss(model(X_batch), y_batch).backward()\n",
    "        trainer.step()\n",
    "        trainer.zero_grad()\n",
    "\n",
    "    p_acc = evaluate_accuracy(model, iter_test)\n",
    "    print('epoch {}, p-acc {:.4f}'.format(epoch + 1, p_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}